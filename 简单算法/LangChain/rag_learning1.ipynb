{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fcdfbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_community.embeddings import DashScopeEmbeddings \n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import bs4\n",
    "from langchain import hub\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8710695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INDEXING ####\n",
    "\n",
    "# Load Documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be2ad295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\.conda\\envs\\langchain-env\\lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down a complex task into smaller, more manageable steps. Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) use step-by-step reasoning to achieve this, enabling better planning and execution. CoT focuses on linear decomposition, while ToT explores multiple reasoning paths in a tree structure.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Embeddings\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "#### RETRIEVAL and GENERATION ####\n",
    "\n",
    "# promote\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# llm\n",
    "# llm = ChatOpenAI(\n",
    "#     base_url=\"https://api.deepseek.com/v1\",\n",
    "#     api_key=os.getenv('DEEPSEEK_API_KEY'),\n",
    "#     model=\"deepseek-chat\"\n",
    "# )\n",
    "# 初始化 DeepSeek 聊天模型\n",
    "# 初始化 DeepSeek 聊天模型\n",
    "llm = init_chat_model(\n",
    "    model=\"deepseek-chat\", \n",
    "    model_provider=\"deepseek\",\n",
    "    api_key=os.getenv('DEEPSEEK_API_KEY')  # 添加这行\n",
    ")\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 被 retriever 用来检索文档。\n",
    "# 被 RunnablePassthrough 原样传递。\n",
    "# 两者结果汇集成字典。\n",
    "# 字典填充 prompt。\n",
    "# prompt 发给 llm。\n",
    "# llm 的回答被 StrOutputParser 解析。\n",
    "# 最终，invoke 方法会返回一个最终的、干净的字符串答案。\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# question\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca8ff9",
   "metadata": {},
   "source": [
    "## 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3116a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents\n",
    "question = \"What kinds of pets do I like?\"\n",
    "document = \"My favorite pet is a cat.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc4bd9",
   "metadata": {},
   "source": [
    "Count tokens considering ~4 char / token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d70a218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9da135",
   "metadata": {},
   "source": [
    "Text embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "719d971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "\n",
    "embd = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "query_result = embd.embed_query(\"What is Task Decomposition?\")\n",
    "document_result = embd.embed_query(\"Task Decomposition is a technique that breaks down a complex task into smaller, more manageable sub-tasks.\")\n",
    "len(query_result)\n",
    "len(document_result)\n",
    "\n",
    "print(len(query_result))\n",
    "print(len(document_result))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c699d4c0",
   "metadata": {},
   "source": [
    "Cosine similarity is reccomended (1 indicates identical) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94a08e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9082681489114193\n"
     ]
    }
   ],
   "source": [
    "# 计算两者的余弦相似度\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(similarity)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e33dd2",
   "metadata": {},
   "source": [
    "Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6536de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文档加载\n",
    "### INDEXING ####\n",
    "\n",
    "# Load blog\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ab5b5",
   "metadata": {},
   "source": [
    "Splitter\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be3bdbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03084330",
   "metadata": {},
   "source": [
    "Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85dc996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=DashScopeEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "669f54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0031cfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
