# =============================================================================
# æ³•å¾‹æ–‡æ¡£æ™ºèƒ½åˆ†æç³»ç»Ÿ - AI Agent å›¢é˜Ÿåä½œå¹³å°
# åŸºäº agno æ¡†æ¶çš„å¤šæ™ºèƒ½ä½“æ³•å¾‹æ–‡æ¡£åˆ†æå·¥å…·
# =============================================================================

# æ ‡å‡†åº“å¯¼å…¥
import os                           # æ“ä½œç³»ç»Ÿæ¥å£æ¨¡å—
import tempfile                     # ä¸´æ—¶æ–‡ä»¶å¤„ç†æ¨¡å—
from dotenv import load_dotenv      # ç¯å¢ƒå˜é‡åŠ è½½å™¨

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import streamlit as st              # Web åº”ç”¨æ¡†æ¶

# agno æ¡†æ¶ç»„ä»¶å¯¼å…¥
from agno.agent import Agent                           # æ™ºèƒ½ä½“æ ¸å¿ƒç±»
from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader  # PDF çŸ¥è¯†åº“å’Œé˜…è¯»å™¨
from agno.vectordb.qdrant import Qdrant              # Qdrant å‘é‡æ•°æ®åº“
from agno.tools.duckduckgo import DuckDuckGoTools     # DuckDuckGo æœç´¢å·¥å…·
from agno.models.openai import OpenAIChat             # OpenAI å…¼å®¹èŠå¤©æ¨¡å‹
from agno.embedder.openai import OpenAIEmbedder       # OpenAI å…¼å®¹åµŒå…¥æ¨¡å‹
from agno.document.chunking.document import DocumentChunking  # æ–‡æ¡£åˆ†å—ç­–ç•¥

# LangChain ç»„ä»¶å¯¼å…¥ï¼ˆå¤‡ç”¨ï¼‰
from langchain.chat_models import init_chat_model      # LangChain èŠå¤©æ¨¡å‹åˆå§‹åŒ–å™¨
from langchain_community.embeddings import DashScopeEmbeddings  # DashScope åµŒå…¥æ¨¡å‹

# =============================================================================
# å…¨å±€é…ç½®å’Œç¯å¢ƒå˜é‡
# =============================================================================

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# åƒé—®ï¼ˆDashScopeï¼‰API é…ç½®
api_key = os.getenv('DASHSCOPE_API_KEY')              # ä»ç¯å¢ƒå˜é‡è¯»å– API Key
base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"  # åƒé—® OpenAI å…¼å®¹æ¥å£
chat_model = "qwen-plus"                               # ä½¿ç”¨çš„èŠå¤©æ¨¡å‹åç§°

# =============================================================================
# å…¨å±€å¸¸é‡å®šä¹‰
# =============================================================================

COLLECTION_NAME = "legal_documents"  # Qdrant å‘é‡æ•°æ®åº“ä¸­çš„é›†åˆåç§°

# =============================================================================
# Streamlit ä¼šè¯çŠ¶æ€åˆå§‹åŒ–å‡½æ•°
# =============================================================================

def init_session_state():
    """åˆå§‹åŒ– Streamlit ä¼šè¯çŠ¶æ€å˜é‡
    
    ä¼šè¯çŠ¶æ€ç”¨äºåœ¨ç”¨æˆ·äº¤äº’è¿‡ç¨‹ä¸­ä¿æŒæ•°æ®æŒä¹…æ€§ï¼Œ
    åŒ…æ‹¬ API å¯†é’¥ã€æ•°æ®åº“è¿æ¥ã€çŸ¥è¯†åº“ã€æ™ºèƒ½ä½“å›¢é˜Ÿç­‰å…³é”®ç»„ä»¶
    """
    # API é…ç½®ç›¸å…³çŠ¶æ€
    if 'openai_api_key' not in st.session_state:
        st.session_state.openai_api_key = None        # OpenAI API Keyï¼ˆå®é™…å­˜å‚¨ DashScope Keyï¼‰
    
    if 'qdrant_api_key' not in st.session_state:
        st.session_state.qdrant_api_key = None        # Qdrant å‘é‡æ•°æ®åº“ API Key
    
    if 'qdrant_url' not in st.session_state:
        st.session_state.qdrant_url = None            # Qdrant æœåŠ¡å™¨ URL
    
    # æ ¸å¿ƒç»„ä»¶çŠ¶æ€
    if 'vector_db' not in st.session_state:
        st.session_state.vector_db = None             # Qdrant å‘é‡æ•°æ®åº“å®ä¾‹
    
    if 'legal_team' not in st.session_state:
        st.session_state.legal_team = None            # æ³•å¾‹æ™ºèƒ½ä½“å›¢é˜Ÿï¼ˆå›¢é˜Ÿåè°ƒè€…ï¼‰
    
    if 'knowledge_base' not in st.session_state:
        st.session_state.knowledge_base = None        # PDF çŸ¥è¯†åº“å®ä¾‹
    
    # æ–‡ä»¶å¤„ç†çŠ¶æ€è¿½è¸ª
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = set()      # å·²å¤„ç†æ–‡ä»¶åé›†åˆï¼ˆé˜²é‡å¤å¤„ç†ï¼‰




def init_qdrant():
    """Initialize Qdrant client with configured settings."""
    if not all([st.session_state.qdrant_api_key, st.session_state.qdrant_url]):
        return None
    try:
        # Create Agno's Qdrant instance which implements VectorDb
        vector_db = Qdrant(
            collection=COLLECTION_NAME,
            url="https://525830b4-3563-4709-90dd-a8fb3062a921.us-west-2-0.aws.cloud.qdrant.io:6333",
            api_key="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.Bbi4iks1zDmPpyFfmNvFub-EHMuagq2AIqQm43xHsR8",
            embedder=OpenAIEmbedder(
                id="text-embedding-3-small",
                api_key="sk-475a692cd53a4a9980b5e0128aa7a57e",
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
            )
        )
        return vector_db
    except Exception as e:
        st.error(f"ğŸ”´ Qdrant connection failed: {str(e)}")
        return None
    
def process_document(uploaded_file, vector_db: Qdrant):
    """
    Process document, create embeddings and store in Qdrant vector database
    
    Args:
        uploaded_file: Streamlit uploaded file object
        vector_db (Qdrant): Initialized Qdrant instance from Agno
    
    Returns:
        PDFKnowledgeBase: Initialized knowledge base with processed documents
    """

    if not st.session_state.openai_api_key:
        
        raise ValueError("OpenAI API key not provided")
    
    os.environ['OPENAI_API_KEY'] = st.session_state.openai_api_key
    # Save the uploaded file to a temporary location
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
            temp_file.write(uploaded_file.getvalue()) # è·å–æ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹,å°†å†…å®¹å†™å…¥ä¸´æ—¶æ–‡ä»¶
            temp_file_path = temp_file.name

        st.info("Loading and processing document...")

        # Create a PDFKnowledgeBase with the vector_db
        knowledge_base = PDFKnowledgeBase(
            path=temp_file_path,  # Single string path, not a list
            vector_db=vector_db,
            reader=PDFReader(),
            chunking_strategy=DocumentChunking(
                chunk_size=1000,
                overlap=200
            )
        )
        # PDFKnowledgeBase should auto-load documents when initialized with path
        st.success("Documents loaded successfully!") 
                
        # Clean up the temporary file
        try:
            os.unlink(temp_file_path)
        except Exception:
            pass
            
        return knowledge_base               
    except Exception as e:
        st.error(f"Document processing error: {str(e)}")
        raise Exception(f"Error processing document: {str(e)}")
    

def main():
    st.set_page_config(page_title="Legal Document Analyzer", layout="wide")
    init_session_state()

    st.title("AI Legal Agent Team ğŸ‘¨â€âš–ï¸")

    with st.sidebar:
        st.header("ğŸ”‘ API Configuration")
        openai_key = st.text_input(
            "OpenAI API Key",
            type="password",
            value=st.session_state.openai_api_key if st.session_state.openai_api_key else "",
            help="Enter your OpenAI API key"
        )
        if openai_key:
            st.session_state.openai_api_key = openai_key
            
        qdrant_key = st.text_input(
            "Qdrant API Key",
            type="password",
            value=st.session_state.qdrant_api_key if st.session_state.qdrant_api_key else "",
            help="Enter your Qdrant API key"
        )
        if qdrant_key:
            st.session_state.qdrant_api_key = qdrant_key
        
        qdrant_url = st.text_input(
            "Qdrant URL",
            value=st.session_state.qdrant_url if st.session_state.qdrant_url else "",
            help="Enter your Qdrant instance URL"
        )
        if qdrant_url:
            st.session_state.qdrant_url = qdrant_url
        
        if all([st.session_state.qdrant_api_key, st.session_state.qdrant_url]):
            try:
                if not st.session_state.vector_db:
                    # Make sure we're initializing a QdrantClient here
                    st.session_state.vector_db = init_qdrant()
                    if st.session_state.vector_db:
                        st.success("Successfully connected to Qdrant!")
            except Exception as e:
                st.error(f"Failed to connect to Qdrant: {str(e)}")

        st.divider()
        if all([st.session_state.openai_api_key, st.session_state.vector_db]):
            st.header("ğŸ“„ Document Upload")
            uploaded_file = st.file_uploader("Upload Legal Document", type=['pdf'])

            if uploaded_file:

                if uploaded_file.name not in st.session_state.processed_files:
                    with st.spinner("Processing document..."):
                        try:
                            knowledge_base = process_document(uploaded_file, st.session_state.vector_db)
                            if knowledge_base:
                                st.session_state.knowledge_base = knowledge_base

                                # Add the file to processed files   
                                # è¿™è¡Œä»£ç æ˜¯ç”¨æ¥é˜²æ­¢é‡å¤å¤„ç†åŒä¸€ä¸ªæ–‡ä»¶çš„ã€‚
                                st.session_state.processed_files.add(uploaded_file.name)

                                # åˆå§‹åŒ–æ™ºèƒ½ä½“
                                # Initialize agents
                                legal_researcher = Agent(
                                name="Legal Researcher",
                                role="Legal research specialist",
                                model=OpenAIChat(
                                    id = "qwen-plus",
                                    base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1",
                                    api_key = st.session_state.openai_api_key
                                ),
                                tools=[DuckDuckGoTools()],
                                knowledge=st.session_state.knowledge_base,
                                search_knowledge=True,
                                instructions=[
                                    "Find and cite relevant legal cases and precedents",
                                    "Provide detailed research summaries with sources",
                                    "Reference specific sections from the uploaded document",
                                    "Always search the knowledge base for relevant information"
                                ],
                                show_tool_calls=True,
                                markdown=True
                            )

                            
                                contract_reviewer = Agent(
                                name="Contract Reviewer",
                                role="Contract review specialist",
                                model=OpenAIChat(
                                    id = "qwen-plus",
                                    base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1",
                                    api_key = st.session_state.openai_api_key
                                ),
                                knowledge=st.session_state.knowledge_base,
                                search_knowledge=True,
                                instructions=[
                                        "Review contracts thoroughly",
                                        "Identify key terms and potential issues",
                                        "Reference specific clauses from the document"
                                    ],
                                markdown=True
                            
                            )

                                legal_strategist = Agent(
                                name="Legal Strategist",
                                role="Legal strategy specialist",
                                model=OpenAIChat(
                                    id = "qwen-plus",
                                    base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1",
                                    api_key = st.session_state.openai_api_key
                                ),
                                knowledge=st.session_state.knowledge_base,
                                search_knowledge=True,
                                instructions=[
                                        "Develop comprehensive legal strategies",
                                        "Provide actionable recommendations",
                                        "Consider both risks and opportunities"
                                    ],
                                markdown=True
                            )

                                st.session_state.legal_team = Agent(
                                    name="Legal Team",
                                    role="Legal team coordinator",
                                    model=OpenAIChat(
                                        id = "qwen-plus",
                                        base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1",
                                        api_key = st.session_state.openai_api_key
                                    ),
                                    team=[legal_researcher, contract_reviewer, legal_strategist],
                                knowledge=st.session_state.knowledge_base,
                                search_knowledge=True,
                                instructions=[
                                        "Coordinate analysis between team members",
                                        "Provide comprehensive responses",
                                        "Ensure all recommendations are properly sourced",
                                        "Reference specific parts of the uploaded document",
                                        "Always search the knowledge base before delegating tasks"
                                    ],
                                markdown=True
                            )
                                st.success("âœ… Document processed and team initialized!")

                        except Exception as e:
                            st.error(f"Error processing document: {str(e)}")

                else:
                    # File already processed, just show a message
                    st.success("âœ… Document already processed and team ready!")
            st.divider()
            st.header("Analysis options")
            analysis_type = st.selectbox(
                        "Select Analysis Type",
                        [
                            "Contract Review",
                            "Legal Research",
                            "Risk Assessment",
                            "Compliance Check",
                            "Custom Query"
                        ]
            )
        else:
            st.warning("Please configure all API credentials to proceed")
    # # Main content area
    if not all([st.session_state.openai_api_key, st.session_state.vector_db]):
        st.info("Please configure all API credentials to proceed")
    elif not uploaded_file:
        st.info("ğŸ‘ˆ Please upload a legal document to begin analysis")
    
    elif st.session_state.legal_team:
        # Create a dictionary for analysis type icons
        analysis_icons = {
            "Contract Review": "ğŸ“‘",
            "Legal Research": "ğŸ”",
            "Risk Assessment": "âš ï¸",
            "Compliance Check": "âœ…",
            "Custom Query": "ğŸ’­"
        }
        # Dynamic header with icon  
        st.header(f"{analysis_icons[analysis_type]} {analysis_type} Analysis")
        # Dynamic header with icon
        st.header(f"{analysis_icons[analysis_type]} {analysis_type} Analysis")
  
        analysis_configs = {
            "Contract Review": {
                "query": "Review this contract and identify key terms, obligations, and potential issues.",
                "agents": ["Contract Analyst"],
                "description": "Detailed contract analysis focusing on terms and obligations"
            },
            "Legal Research": {
                "query": "Research relevant cases and precedents related to this document.",
                "agents": ["Legal Researcher"],
                "description": "Research on relevant legal cases and precedents"
            },
            "Risk Assessment": {
                "query": "Analyze potential legal risks and liabilities in this document.",
                "agents": ["Contract Analyst", "Legal Strategist"],
                "description": "Combined risk analysis and strategic assessment"
            },
            "Compliance Check": {
                "query": "Check this document for regulatory compliance issues.",
                "agents": ["Legal Researcher", "Contract Analyst", "Legal Strategist"],
                "description": "Comprehensive compliance analysis"
            },
            "Custom Query": {
                "query": None,
                "agents": ["Legal Researcher", "Contract Analyst", "Legal Strategist"],
                "description": "Custom analysis using all available agents"
            }
        }
        # Replace the existing user_query section with this:

        if analysis_type == "Custom Query":
            user_query = st.text_area(
                "Enter your specific query:",
                help="Add any specific questions or points you want to analyze"
            )
        else:
            user_query = None  # Set to None for non-custom queries
        

        if st.button("Analyze"):
            if analysis_type == "Custom Query" and not user_query:
                st.warning("Please enter a query")
            else:
                with st.spinner("Analyzing document..."):
                    try:
                        # Ensure OpenAI API key is set
                        os.environ['OPENAI_API_KEY'] = st.session_state.openai_api_key
                        
                        # Combine predefined and user queries
                        if analysis_type != "Custom Query":
                            combined_query = f"""
                            Using the uploaded document as reference:
                            
                            Primary Analysis Task: {analysis_configs[analysis_type]['query']}
                            Focus Areas: {', '.join(analysis_configs[analysis_type]['agents'])}
                            
                            Please search the knowledge base and provide specific references from the document.
                            """
                        else:
                            combined_query = f"""
                            Using the uploaded document as reference:
                            
                            {user_query}
                            
                            Please search the knowledge base and provide specific references from the document.
                            Focus Areas: {', '.join(analysis_configs[analysis_type]['agents'])}
                            """

                        response = st.session_state.legal_team.run(combined_query)
                        
                        # Display results in tabs
                        tabs = st.tabs(["Analysis", "Key Points", "Recommendations"])
                        
                        with tabs[0]:
                            st.markdown("### Detailed Analysis")
                            if response.content:
                                st.markdown(response.content)
                            else:
                                for message in response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)
                        
                        with tabs[1]:
                            st.markdown("### Key Points")
                            key_points_response = st.session_state.legal_team.run(
                                f"""Based on this previous analysis:    
                                {response.content}
                                
                                Please summarize the key points in bullet points.
                                Focus on insights from: {', '.join(analysis_configs[analysis_type]['agents'])}"""
                            )
                            if key_points_response.content:
                                st.markdown(key_points_response.content)
                            else:
                                for message in key_points_response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)
                        
                        with tabs[2]:
                            st.markdown("### Recommendations")
                            recommendations_response = st.session_state.legal_team.run(
                                f"""Based on this previous analysis:
                                {response.content}
                                
                                What are your key recommendations based on the analysis, the best course of action?
                                Provide specific recommendations from: {', '.join(analysis_configs[analysis_type]['agents'])}"""
                            )
                            if recommendations_response.content:
                                st.markdown(recommendations_response.content)
                            else:
                                for message in recommendations_response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)

                    except Exception as e:
                        st.error(f"Error during analysis: {str(e)}")
    else:
        st.info("Please upload a legal document to begin analysis")






if __name__ == "__main__":
    main() 
                                    


