{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:32:23.473163Z",
     "start_time": "2025-07-30T11:32:16.647205Z"
    }
   },
   "source": [
    "import hashlib\n",
    "import hashlib\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from torch.optim import AdamW\n",
    "class Config:\n",
    "    train_path = './DuReaderQG/train.json'\n",
    "    valid_path = './DuReaderQG/dev.json'\n",
    "    model_path = './models/langboat/mengzi-t5-base'\n",
    "    save_dir = './best_model'\n",
    "    max_source_length = 1024\n",
    "    max_target_length = 128\n",
    "    batch_size = 4\n",
    "    accum_steps = 4\n",
    "    epochs = 30\n",
    "    val_samples_per_epoch = 1\n",
    "    seed = 42\n",
    "    valid_shuffle = True  \n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(Config.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:32:26.495263Z",
     "start_time": "2025-07-30T11:32:26.430374Z"
    }
   },
   "id": "b67d4b6be0bdd061",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# 数据加载\n",
    "import json\n",
    "def load_train_data(path):\n",
    "    # 加载训练数据 \n",
    "    with open(path,'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f if line.strip()]\n",
    "train_data = load_train_data(Config.train_path)\n",
    "print(len(train_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:32:36.215981Z",
     "start_time": "2025-07-30T11:32:36.098317Z"
    }
   },
   "id": "6a9dd8e1bc9f6b9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14520\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "import hashlib\n",
    "def load_valid_data(path):\n",
    "    \"\"\"加载验证数据（合并相同context+question）\"\"\"\n",
    "    grouped = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                sample = json.loads(line)\n",
    "                key = hashlib.md5(\n",
    "                    (sample[\"context\"] + sample[\"question\"]).encode()\n",
    "                ).hexdigest()\n",
    "                if key not in grouped:\n",
    "                    grouped[key] = {\n",
    "                        \"context\": sample[\"context\"],\n",
    "                        \"question\": sample[\"question\"],\n",
    "                        \"answers\": [],\n",
    "                        \"ids\": []\n",
    "                    }\n",
    "                grouped[key][\"answers\"].append(sample[\"answer\"])\n",
    "                grouped[key][\"ids\"].append(sample[\"id\"])\n",
    "    return list(grouped.values())\n",
    "\n",
    "\n",
    "valid_data = load_valid_data(Config.valid_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:32:38.345949Z",
     "start_time": "2025-07-30T11:32:38.312750Z"
    }
   },
   "id": "e22fb1bbcc991d40",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-29T15:12:57.572571900Z",
     "start_time": "2025-07-29T15:12:57.567057600Z"
    }
   },
   "id": "239e97b34ba4348b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'context': '年基准利率4.35%。 从实际看,贷款的基本条件是: 一是中国大陆居民,年龄在60岁以下; 二是有稳定的住址和工作或经营地点; 三是有稳定的收入来源; 四是无不良信用记录,贷款用途不能作为炒股,赌博等行为; 五是具有完全民事行为能力。', 'question': '2017年银行贷款基准利率', 'answers': ['年基准利率4.35%', '4.35%'], 'ids': [0, 1]}, {'context': 'U系列是最好的，采用国际顶尖技术（由格力自主研发）双级变频压缩机，提高压缩机运转效率，制冷制热能力更强劲；1赫兹变频技术，使空调相当于一个15 W电灯泡，更加节能省电；送风面积广，风力大；生态风，净化空气。非常不错，现在国美在做活动，可以了解一下。', 'question': '格力空调哪个系列好', 'answers': ['U系列'], 'ids': [2]}]\n"
     ]
    }
   ],
   "source": [
    "print(valid_data[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-29T15:12:57.936874Z",
     "start_time": "2025-07-29T15:12:57.930551700Z"
    }
   },
   "id": "8b57424f2031ce8c"
  },
  {
   "cell_type": "code",
   "source": [
    "class QADataset:\n",
    "    def __init__(self,data,is_train=True):\n",
    "        self.data = data\n",
    "        self.is_train = is_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        if self.is_train:\n",
    "            return {\n",
    "                'context': item['context'],\n",
    "                'question': item['question'],\n",
    "                'answer': item['answer'],\n",
    "                \"id\" : item['id']\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'context': item['context'],\n",
    "                'question': item['question'],\n",
    "                'answers': item['answers'],  # 在验证集上，答案是一个列表\n",
    "                'id': item['ids'][0]\n",
    "            }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:33:14.517034Z",
     "start_time": "2025-07-30T11:33:14.510445Z"
    }
   },
   "id": "bab270c42e31b5ff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = QADataset(train_data, is_train=True)\n",
    "valid_data = QADataset(valid_data, is_train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:35:46.098341Z",
     "start_time": "2025-07-30T11:35:46.094291Z"
    }
   },
   "id": "2a8c24722193ce62",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:33:25.577773Z",
     "start_time": "2025-07-30T11:33:25.571606Z"
    }
   },
   "id": "275e169796d944a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '选择燃气热水器时，一定要关注这几个问题：1、出水稳定性要好，不能出现忽热忽冷的现象2、快速到达设定的需求水温3、操作要智能、方便4、安全性要好，要装有安全报警装置 市场上燃气热水器品牌众多，购买时还需多加对比和仔细鉴别。方太今年主打的磁化恒温热水器在使用体验方面做了全面升级：9秒速热，可快速进入洗浴模式；水温持久稳定，不会出现忽热忽冷的现象，并通过水量伺服技术将出水温度精确控制在±0.5℃，可满足家里宝贝敏感肌肤洗护需求；配备CO和CH4双气体报警装置更安全（市场上一般多为CO单气体报警）。另外，这款热水器还有智能WIFI互联功能，只需下载个手机APP即可用手机远程操作热水器，实现精准调节水温，满足家人多样化的洗浴需求。当然方太的磁化恒温系列主要的是增加磁化功能，可以有效吸附水中的铁锈、铁屑等微小杂质，防止细菌滋生，使沐浴水质更洁净，长期使用磁化水沐浴更利于身体健康。',\n",
       " 'question': '燃气热水器哪个牌子好',\n",
       " 'answer': '方太',\n",
       " 'id': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "valid_data[5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:33:26.253560Z",
     "start_time": "2025-07-30T11:33:26.246883Z"
    }
   },
   "id": "d1b5c3ed9ace90a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '密歇根州。地理位置：密歇根州（Michigan）位于美国最北部，由两大半岛组成，分隔两半岛的水面叫做麦基诺水道。南为下半岛，是该州的主体，面积较大，其南境西半部接印第安纳州，东半部接俄亥俄州。半岛西、北、东三方面均为湖泊，西、北为密歇根湖，东北为休伦湖，东为圣克莱尔湖与圣克莱尔河，东南是伊利湖。北部为上半岛，面积比下半岛小，北滨苏必利尔湖，南临密歇根湖，西南邻威斯康星州，东端为圣马里斯河及苏运河。气候与面积：州面积250,493平方公里，居美国50州第11位。位于五大湖区，受湖风调剂，气候温和。北方的苏圣玛丽城平均最高温度为10℃，平均最低温度为-1℃。东南部的底特律市平均最高温度为14℃，平均最低温度为6℃。上半岛的生长期约为3个月，而下半岛的南部地区长达6个月。年平均降水量838毫米，南部较多，达914毫米。城市与人口：人口987.6万（2011年），居全美第8位，白人占总人口的79.6%，黑人占14%。密州有83个郡，州府兰辛市（Lansing），人口11.6万，为州政治、文化及教育中心。底特律（Detroit）是密州最大城市，人口87万。大底特律地区华侨华人较为集中。历史：17世纪时为印第安人居住地，1668年法国殖民者建立第一个定居点，1701年底特律成为皮毛贸易中心，1783年以后归属美国。1837年加入联邦，成为美国第26个州。',\n",
       " 'question': 'mi是美国哪个州的缩写',\n",
       " 'answers': ['密歇根州', '密歇根州（Michigan）', 'Michigan'],\n",
       " 'id': 8}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# 定义验证集分块器，在实际开发中由于验证集通常较小，分块器的作用是将验证集划分为多个小块，\n",
    "# 以便在每个epoch中使用不同的验证样本进行评估。\n",
    "\n",
    "import torch\n",
    "class ValidChunk():\n",
    "    def __init__(self,dataset,epochs):\n",
    "        self.dataset = dataset\n",
    "        self.total_samples = len(dataset)\n",
    "        self.total_epochs = epochs\n",
    "        self.samples_per_epoch = self.total_samples // epochs\n",
    "        self.indices = torch.arange(0, self.total_samples).tolist()\n",
    "        \n",
    "        \n",
    "        if self.total_samples % epochs != 0:\n",
    "            pad = self.total_epochs - (self.total_samples % epochs)\n",
    "            self.indices += self.indices[:pad]\n",
    "            self.total_samples += pad\n",
    "            \n",
    "            \n",
    "        if Config.valid_shuffle:\n",
    "            random.shuffle(self.indices)\n",
    "    def get_chunk_indices(self, epoch):\n",
    "        start = epoch * self.samples_per_epoch\n",
    "        end = start + self.samples_per_epoch\n",
    "        return self.indices[start:end]\n",
    "valid_chunker = ValidChunk(valid_data, Config.epochs) # 后期实际上没有调用,\n",
    "tokenizer = AutoTokenizer.from_pretrained(Config.model_path) # 分词器\n",
    "\n",
    "def train_collate(batch):\n",
    "    \"\"\"收集每一个batch的训练数据\"\"\"\n",
    "    inputs = [f\"question:{item['question']} context:{item['context']}\" for item in batch]\n",
    "    targets = [item['answer'] for item in batch]\n",
    "    \n",
    "    source = tokenizer(inputs, \n",
    "                        max_length=Config.max_source_length, \n",
    "                        padding='max_length', \n",
    "                        truncation=True, \n",
    "                        return_tensors='pt')\n",
    "    target = tokenizer(targets,\n",
    "                        max_length=Config.max_target_length, \n",
    "                        padding='max_length', \n",
    "                        truncation=True, \n",
    "                        return_tensors='pt').input_ids\n",
    "    \n",
    "    target[target == tokenizer.pad_token_id] = -100  # 忽略填充部分\n",
    "    return {\n",
    "        'input_ids': source.input_ids,\n",
    "        'attention_mask': source.attention_mask,\n",
    "        'labels': target\n",
    "    }\n",
    "def valid_collates(batch):\n",
    "    \"\"\"收集每一个batch的验证数据\"\"\"\n",
    "    inputs = [f\"question:{item['question']} context:{item['context']}\" for item in batch]\n",
    "    processed = tokenizer(\n",
    "        inputs,\n",
    "        max_length=Config.max_source_length,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': processed.input_ids,\n",
    "        'attention_mask': processed.attention_mask,\n",
    "        'ids': [item['id'] for item in batch],  # 保留ID以便后续使用\n",
    "        'context': [item['context'] for item in batch],\n",
    "        'question': [item['question'] for item in batch],\n",
    "        'answers': [item['answers'] for item in batch]  # 保留答案\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T12:55:53.961467Z",
     "start_time": "2025-07-30T12:55:53.232280Z"
    }
   },
   "id": "503da9de8576431a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d916f57e76f3ef91"
  },
  {
   "cell_type": "code",
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(Config.model_path).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:35:46.051553Z",
     "start_time": "2025-07-30T11:33:58.405958Z"
    }
   },
   "id": "cb65a887e3a7a072",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "#定义优化器\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:46.219756Z",
     "start_time": "2025-07-30T12:54:46.167029Z"
    }
   },
   "id": "44dcb843a4fca907",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_collate\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-30T12:55:57.247504Z",
     "start_time": "2025-07-30T12:55:57.241578Z"
    }
   },
   "id": "bc0b6a43a4961d26",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:56:02.277150Z",
     "start_time": "2025-07-30T12:56:02.268316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 整个数据集在每一个epoch中都被分成了多个小批次，len(train_loader) 是mini-batch的数量\n",
    "num_training_steps = len(train_loader) * Config.epochs // Config.accum_steps\n",
    "# 预热步数\n",
    "num_warmup_steps = int(0.1 * num_training_steps)  # 10% warmup，可调\n",
    "# 定义学习率调度器\n",
    "schecduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ],
   "id": "6af3c31d2ffee959",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:56:26.994825Z",
     "start_time": "2025-07-30T12:56:26.008347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "\n",
    "class BleuEvaluator:\n",
    "    def __init__(self):\n",
    "        self.smooth = SmoothingFunction().method1\n",
    "        self.weights = {\n",
    "            1: (1, 0, 0, 0),\n",
    "            2: (0.5, 0.5, 0, 0),\n",
    "            3: (1/3, 1/3, 1/3, 0),\n",
    "            4: (0.25, 0.25, 0.25, 0.25)\n",
    "        }\n",
    "\n",
    "    def calc_bleu(self, pred, refs):\n",
    "        pred_tokens = list(pred.strip())\n",
    "        ref_tokens = [list(r.strip()) for r in refs]\n",
    "        return {\n",
    "            f\"BLEU-{n}\": sentence_bleu(\n",
    "                ref_tokens, pred_tokens,\n",
    "                weights=self.weights[n],\n",
    "                smoothing_function=self.smooth\n",
    "            ) for n in range(1, 5)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def dynamic_score(scores, pred_len):\n",
    "        if pred_len <= 2:\n",
    "            return scores[\"BLEU-1\"] * 0.6 + scores[\"BLEU-2\"] * 0.4\n",
    "        elif 3 <= pred_len <= 5:\n",
    "            return scores[\"BLEU-2\"] * 0.5 + scores[\"BLEU-3\"] * 0.3 + scores[\"BLEU-4\"] * 0.2\n",
    "        else:\n",
    "            return scores[\"BLEU-4\"] * 0.7 + scores[\"BLEU-3\"] * 0.3"
   ],
   "id": "fc54c2660b5512e8",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:56:31.653345Z",
     "start_time": "2025-07-30T12:56:31.577629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 假设你已经定义好 train_dataloader\n",
    "batch = next(iter(train_loader))  # train_loader 就是你的 DataLoader 对象\n"
   ],
   "id": "83e0128c8c25686",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:13:46.512298Z",
     "start_time": "2025-07-30T13:13:46.502928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 将张量移动到 CPU，便于查看\n",
    "for key, value in batch.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(value if isinstance(value, list) else value.shape)\n",
    "    print(\"-\" * 50)"
   ],
   "id": "e662adea9140a4c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "torch.Size([4, 1024])\n",
      "--------------------------------------------------\n",
      "attention_mask:\n",
      "torch.Size([4, 1024])\n",
      "--------------------------------------------------\n",
      "labels:\n",
      "torch.Size([4, 128])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:33:26.182094Z",
     "start_time": "2025-07-30T13:33:26.170865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"input示例\")\n",
    "print(batch[\"input_ids\"][0]) # 第一个样本'input_ids'"
   ],
   "id": "4b634216913e3906",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input示例\n",
      "tensor([   7, 3454, 2055,  ...,    0,    0,    0])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T14:47:37.237592Z",
     "start_time": "2025-07-30T14:47:37.218894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"解码为文本:\")\n",
    "print(tokenizer.decode(batch[\"input_ids\"][0], skip_special_tokens=True))"
   ],
   "id": "d3235d9a83fd33ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解码为文本:\n",
      "question:人力资源管理专业属于什么类 context:人力资源管理专业学科:管理学 (Management)门类:工商管理类(Mater of Business Administration)专业名称:人力资源管理 (Human Resources Management)业务培养目标:本专业培养具备管理、经济、法律及人力资源管理等方面的知识和能力,能在事业单位及政府部门从事人力资源管理以及教学、科研方面工作的工商管理学科高级专门人才。业务培养要求:本专业学生上要学习管理学、经济学及人力资源管理方面的基本理论和基本知识,受到人力资源管理方法与技巧方面的基本训练,具有分析和解决人力资源管理问题的基本能力。毕业生应获得以下几方面的知识和能力:1.掌握管理学、经济学及人力资源管理的基本理论、基本知识;2.掌握人力资源管理的定性、定量分析方法;3.具有较强的语言与文字表达、人际沟通、组织协调及领导的基本能力;4.熟悉与人力资源管理有关的方针、政策及法规;5.了解本学科理论前沿与发展动态;6.掌握文献检索、资料查询的基本方法,具有一定科学研究和实际工作能力。主干学科:经济学、工商管理主要课程:管理学、微观经济学、宏观经济学、管理信息系统,统计学、会计学、财务管理、市场营销、经济法、人力资源管理、组织行为学、劳动经济学。 主要实践性教学环节:包括课程实习与毕业实习,一般安排10-12周。修业年限:四年授予学位:管理学学士(荣誉生)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T14:48:28.027617Z",
     "start_time": "2025-07-30T14:48:28.015823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nlabels 示例:\")\n",
    "print(batch[\"labels\"][0])\n",
    "print(\"解码为文本:\")\n",
    "label_ids = batch[\"labels\"][0]\n",
    "# 替换掉 -100（忽略值）为 pad_token_id，再解码\n",
    "label_ids = [id if id != -100 else tokenizer.pad_token_id for id in label_ids]\n",
    "print(tokenizer.decode(label_ids, skip_special_tokens=True))"
   ],
   "id": "f776ebe3a844739d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "labels 示例:\n",
      "tensor([    7, 20829,   373,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "解码为文本:\n",
      "工商管理类\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "best_dynamic = 0.0\n",
    "loss_history = []\n",
    "lr_history = []\n",
    "bleu1_history = []\n",
    "bleu2_history = []\n",
    "bleu3_history = []\n",
    "bleu4_history = []\n",
    "dynamic_history = []\n",
    "\n",
    "def validate(loader):\n",
    "    evaluator = BleuEvaluator()\n",
    "    all_bleu = []\n",
    "    all_dynamic = []\n",
    "    displayed = set()\n",
    "\n",
    "    for batch in loader:\n",
    "        inputs = batch[\"input_ids\"].to(device)\n",
    "        generated = model.generate(\n",
    "            inputs,\n",
    "            max_length=Config.max_target_length,\n",
    "            num_beams=5,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        preds = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "\n",
    "        for i, (pred, refs) in enumerate(zip(preds, batch[\"answers\"])):\n",
    "            bleu = evaluator.calc_bleu(pred, refs)\n",
    "            all_bleu.append(bleu)\n",
    "\n",
    "            pred_len = len(list(pred.strip()))\n",
    "            dynamic = BleuEvaluator.dynamic_score(bleu, pred_len)\n",
    "            all_dynamic.append(dynamic)\n",
    "\n",
    "    avg_bleu = {\n",
    "        f\"BLEU-{n}\": np.mean([b[f\"BLEU-{n}\"] for b in all_bleu]) * 100\n",
    "        for n in range(1, 5)\n",
    "    }\n",
    "    avg_dynamic = np.mean(all_dynamic) * 100\n",
    "    return avg_bleu, avg_dynamic"
   ],
   "id": "eab1e5fd18b79bdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_model(epoch, dynamic_score):\n",
    "    save_path = Path(Config.save_dir) / f\"epoch_{epoch}_dynamic_{dynamic_score:.2f}\"\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    print(f\"\\n模型保存至: {save_path}\")\n"
   ],
   "id": "d46e2d15296777ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
